# Cadeia-de-Pensamento Prompt

## Cadeia-de-Pensamento (CoT) Prompting

> Fonte da imagem: Wei et al. (2022)

Introduzido em Wei et al. (2022), a **solicitação de cadeia de pensamento (Chain-of-Thought - CoT)** permite **recursos de raciocínio complexos** por meio de etapas intermediárias de raciocínio. Você pode combiná-la com prompts de poucos tiros para obter melhores resultados em tarefas mais complexas que exigem raciocínio antes de responder.

---

### Exemplo de Prompt CoT Few-Shot:

**Prompt:**
```
Os números ímpares neste grupo somam um número par: 4, 8, 9, 15, 12, 2, 1.  
R: Somando todos os números ímpares (9, 15, 1) dá 25. A resposta é Falso.  
Os números ímpares neste grupo somam um número par: 17, 10, 19, 4, 8, 12, 24.  
R: Somando todos os números ímpares (17, 19) dá 36. A resposta é Verdadeiro.  
Os números ímpares neste grupo somam um número par: 16, 11, 14, 4, 8, 13, 24.  
R: Somando todos os números ímpares (11, 13) dá 24. A resposta é Verdadeiro.  
Os números ímpares neste grupo somam um número par: 17, 9, 10, 12, 13, 4, 2.  
R: Somando todos os números ímpares (17, 9, 13) dá 39. A resposta é Falso.  
Os números ímpares neste grupo somam um número par: 15, 32, 5, 13, 82, 7, 1.  
A:
```

**Saída:**
```
Somando todos os números ímpares (15, 5, 13, 7, 1) dá 41. A resposta é Falso.
```

> Uau! Podemos ver um resultado perfeito quando fornecemos a etapa de raciocínio.

---

### Exemplo com Apenas Um Exemplo (1-shot CoT):

**Prompt:**
```
Os números ímpares neste grupo somam um número par: 4, 8, 9, 15, 12, 2, 1.  
R: Somando todos os números ímpares (9, 15, 1) dá 25. A resposta é Falso.  
Os números ímpares neste grupo somam um número par: 15, 32, 5, 13, 82, 7, 1.  
A:
```

**Saída:**
```
Somando todos os números ímpares (15, 5, 13, 7, 1) dá 41. A resposta é Falso.
```

> Isso mostra que **apenas uma demonstração pode ser suficiente** quando CoT é utilizado corretamente.

> Os autores destacam que essa é uma **habilidade emergente**, que só aparece em **modelos de linguagem suficientemente grandes**.

---

## Prompt CoT Zero-Shot

> Fonte da imagem: Kojima et al. (2022)

Uma ideia mais recente é o **Zero-Shot CoT**, introduzido por Kojima et al. (2022), que envolve essencialmente **adicionar a frase "Vamos pensar passo a passo"** ao final do prompt original. Vamos ver como isso afeta o desempenho do modelo.

---

### Exemplo sem CoT:

**Prompt:**
```
Fui ao mercado e comprei 10 maçãs. Dei 2 maçãs ao vizinho e 2 ao reparador. Então fui comprar mais 5 maçãs e comi 1. Com quantas maçãs fiquei?
```

**Saída:**
```
11 maçãs
```

> A resposta está incorreta.

---

### Exemplo com CoT Zero-Shot:

**Prompt:**
```
Fui ao mercado e comprei 10 maçãs. Dei 2 maçãs ao vizinho e 2 ao reparador. Então fui comprar mais 5 maçãs e comi 1. Com quantas maçãs fiquei?  
Vamos pensar passo a passo.
```

**Saída:**
```
Primeiro, você começou com 10 maçãs.  
Você deu 2 maçãs para o vizinho e 2 para o reparador, então você tinha 6 maçãs sobrando.  
Então você comprou mais 5 maçãs, então agora você tinha 11 maçãs.  
Finalmente, você comeu 1 maçã, então ficaria com 10 maçãs.
```

> É impressionante que **esse simples acréscimo** ("Vamos pensar passo a passo") seja **tão eficaz** para tarefas que exigem raciocínio.

---

### Conclusão

- A **Cadeia de Pensamento** (CoT) permite que o modelo **divida tarefas complexas em etapas lógicas**.
- Pode ser usada tanto em **few**
